#!/usr/bin/env python3
"""
Test et diagnostic Ollama pour ALMAA
"""

import subprocess
import time
import requests
import ollama
import os
from pathlib import Path


def check_ollama_process():
    """V√©rifier si Ollama est en cours d'ex√©cution"""
    try:
        result = subprocess.run(['tasklist'], capture_output=True, text=True, shell=True)
        if 'ollama.exe' in result.stdout:
            print("‚úÖ Processus Ollama d√©tect√©")
            return True
        else:
            print("‚ùå Processus Ollama non trouv√©")
            return False
    except Exception as e:
        print(f"‚ùå Erreur v√©rification processus: {e}")
        return False


def check_ollama_port():
    """V√©rifier si Ollama √©coute sur le port 11434"""
    try:
        result = subprocess.run(['netstat', '-an'], capture_output=True, text=True, shell=True)
        if ':11434' in result.stdout:
            print("‚úÖ Port 11434 ouvert")
            return True
        else:
            print("‚ùå Port 11434 non trouv√©")
            return False
    except Exception as e:
        print(f"‚ùå Erreur v√©rification port: {e}")
        return False


def test_ollama_api():
    """Tester l'API Ollama"""
    urls_to_try = [
        'http://localhost:11434/api/version',
        'http://127.0.0.1:11434/api/version',
        'http://0.0.0.0:11434/api/version'
    ]
    
    for url in urls_to_try:
        try:
            response = requests.get(url, timeout=5)
            if response.status_code == 200:
                print(f"‚úÖ API Ollama accessible via {url}")
                print(f"   Version: {response.json()}")
                return True
        except Exception as e:
            print(f"‚ùå API {url} non accessible: {e}")
            
    return False


def test_ollama_python():
    """Tester Ollama via Python"""
    hosts_to_try = [
        'http://localhost:11434',
        'http://127.0.0.1:11434',
        'http://0.0.0.0:11434'
    ]
    
    for host in hosts_to_try:
        try:
            client = ollama.Client(host=host)
            response = client.generate(
                model='solar:10.7b',
                prompt='Test',
                options={'num_predict': 3}
            )
            print(f"‚úÖ Ollama Python OK via {host}")
            print(f"   Response: {response['response']}")
            return True
        except Exception as e:
            print(f"‚ùå Ollama Python {host}: {e}")
            
    return False


def restart_ollama():
    """Red√©marrer Ollama proprement"""
    print("üîÑ Red√©marrage d'Ollama...")
    
    # Arr√™ter tous les processus Ollama
    try:
        subprocess.run(['taskkill', '/f', '/im', 'ollama.exe'], 
                      capture_output=True, shell=True)
        print("   Arr√™t des processus Ollama...")
        time.sleep(3)
    except:
        pass
    
    # Red√©marrer Ollama en arri√®re-plan
    try:
        print("   D√©marrage d'Ollama serve...")
        # Utiliser Popen pour d√©marrer en arri√®re-plan
        process = subprocess.Popen(
            ['ollama', 'serve'],
            stdout=subprocess.DEVNULL,
            stderr=subprocess.DEVNULL
        )
        time.sleep(5)  # Attendre le d√©marrage
        
        # V√©rifier si √ßa marche
        if test_ollama_api():
            print("‚úÖ Ollama red√©marr√© avec succ√®s")
            return True
        else:
            print("‚ùå √âchec du red√©marrage")
            return False
            
    except Exception as e:
        print(f"‚ùå Erreur red√©marrage: {e}")
        return False


def main():
    """Diagnostic complet d'Ollama"""
    print("üîç DIAGNOSTIC OLLAMA POUR ALMAA")
    print("=" * 50)
    
    # √âtape 1: Processus
    print("\n1. V√©rification processus:")
    process_ok = check_ollama_process()
    
    # √âtape 2: Port
    print("\n2. V√©rification port:")
    port_ok = check_ollama_port()
    
    # √âtape 3: API
    print("\n3. Test API:")
    api_ok = test_ollama_api()
    
    # √âtape 4: Python
    print("\n4. Test Python:")
    python_ok = test_ollama_python()
    
    # R√©sum√©
    print("\n" + "=" * 50)
    print("üìä R√âSUM√â:")
    
    if all([process_ok, port_ok, api_ok, python_ok]):
        print("‚úÖ Ollama fonctionne parfaitement!")
        print("   Le probl√®me vient d'ailleurs dans ALMAA")
        return True
        
    elif process_ok and not (port_ok and api_ok):
        print("‚ö†Ô∏è  Ollama lanc√© mais pas accessible")
        print("   Essai de red√©marrage...")
        if restart_ollama():
            return True
        
    elif not process_ok:
        print("‚ùå Ollama non d√©marr√©")
        print("   Essai de d√©marrage...")
        if restart_ollama():
            return True
    
    # Solutions alternatives
    print("\nüí° SOLUTIONS ALTERNATIVES:")
    print("1. D√©marrer manuellement: ollama serve")
    print("2. V√©rifier l'installation: ollama --version")
    print("3. R√©installer Ollama depuis https://ollama.ai")
    
    return False


if __name__ == "__main__":
    success = main()
    
    if success:
        print("\nüéâ OLLAMA OK - Vous pouvez lancer ALMAA:")
        print("   python main_phase2.py interactive")
    else:
        print("\n‚ùå OLLAMA KO - Corrigez les probl√®mes ci-dessus")
        
    input("\nAppuyez sur Entr√©e pour continuer...")